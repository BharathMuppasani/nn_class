{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.animation as animation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv:\n",
    "    def __init__(self, size=10, obstacles=None):\n",
    "        self.size = size\n",
    "        self.obstacles = obstacles if obstacles is not None else []\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self, start=None, goal=None):\n",
    "        \"\"\"Reset environment with optional custom start/goal positions\"\"\"\n",
    "        if start is None:\n",
    "            self.start = self.get_random_position()\n",
    "        else:\n",
    "            self.start = start\n",
    "            \n",
    "        if goal is None:\n",
    "            self.goal = self.get_random_position()\n",
    "            while self.goal == self.start:\n",
    "                self.goal = self.get_random_position()\n",
    "        else:\n",
    "            self.goal = goal\n",
    "            \n",
    "        self.current_pos = self.start\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_random_position(self):\n",
    "        \"\"\"Get random position that's not an obstacle\"\"\"\n",
    "        while True:\n",
    "            pos = (random.randint(0, self.size-1), random.randint(0, self.size-1))\n",
    "            if pos not in self.obstacles:\n",
    "                return pos\n",
    "    \n",
    "    def get_state(self):\n",
    "        \"\"\"Return state as (current_position, goal_position)\"\"\"\n",
    "        return (self.current_pos, self.goal)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take action and return (new_state, reward, done)\"\"\"\n",
    "        # Actions: 0=up, 1=right, 2=down, 3=left\n",
    "        moves = [(-1, 0), (0, 1), (1, 0), (0, -1)]\n",
    "        \n",
    "        # Calculate new position\n",
    "        new_pos = (\n",
    "            self.current_pos[0] + moves[action][0],\n",
    "            self.current_pos[1] + moves[action][1]\n",
    "        )\n",
    "        \n",
    "        # Check if move is valid\n",
    "        if (0 <= new_pos[0] < self.size and \n",
    "            0 <= new_pos[1] < self.size and \n",
    "            new_pos not in self.obstacles):\n",
    "            self.current_pos = new_pos\n",
    "            \n",
    "        # Calculate reward\n",
    "        if self.current_pos == self.goal:\n",
    "            reward = 100\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -1\n",
    "            done = False\n",
    "            \n",
    "        return self.get_state(), reward, done\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, action_space=4, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):\n",
    "        self.q_table = defaultdict(lambda: np.zeros(action_space))\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        \"\"\"Epsilon-greedy action selection\"\"\"\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, 3)\n",
    "        return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"Update Q-value for state-action pair\"\"\"\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.gamma * self.q_table[next_state][best_next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.lr * td_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridVisualizer:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.fig, self.ax = plt.subplots(figsize=(8, 8))\n",
    "        self.images = []\n",
    "        \n",
    "    def draw_grid(self, path=None, current_pos=None):\n",
    "        \"\"\"Draw the grid with optional path and current position\"\"\"\n",
    "        self.ax.clear()\n",
    "        \n",
    "        # Draw grid lines\n",
    "        for i in range(self.env.size + 1):\n",
    "            self.ax.axhline(y=i, color='gray', linestyle='-', alpha=0.3)\n",
    "            self.ax.axvline(x=i, color='gray', linestyle='-', alpha=0.3)\n",
    "            \n",
    "        # Draw obstacles\n",
    "        for obs in self.env.obstacles:\n",
    "            self.ax.add_patch(Rectangle((obs[1], obs[0]), 1, 1, facecolor='gray'))\n",
    "            \n",
    "        # Draw start and goal\n",
    "        self.ax.add_patch(Rectangle((self.env.start[1], self.env.start[0]), 1, 1, facecolor='green', alpha=0.5))\n",
    "        self.ax.add_patch(Rectangle((self.env.goal[1], self.env.goal[0]), 1, 1, facecolor='red', alpha=0.5))\n",
    "        \n",
    "        # Draw path\n",
    "        if path:\n",
    "            path_x = [p[1] + 0.5 for p in path]\n",
    "            path_y = [p[0] + 0.5 for p in path]\n",
    "            self.ax.plot(path_x, path_y, 'b-', linewidth=2, alpha=0.5)\n",
    "            \n",
    "        # Draw current position\n",
    "        if current_pos:\n",
    "            self.ax.add_patch(Rectangle((current_pos[1], current_pos[0]), 1, 1, facecolor='blue', alpha=0.5))\n",
    "            \n",
    "        self.ax.set_xlim(0, self.env.size)\n",
    "        self.ax.set_ylim(0, self.env.size)\n",
    "        self.ax.invert_yaxis()\n",
    "        plt.grid(True)\n",
    "        \n",
    "    def animate_path(self, path, interval=500):\n",
    "        \"\"\"Animate the agent moving along the path\"\"\"\n",
    "        def update(frame):\n",
    "            self.draw_grid(path[:frame+1], path[frame])\n",
    "            return self.ax,\n",
    "            \n",
    "        anim = animation.FuncAnimation(\n",
    "            self.fig, update, frames=len(path),\n",
    "            interval=interval, blit=True, repeat=False\n",
    "        )\n",
    "        plt.close()\n",
    "        return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episodes=1000, visualize_every=100):\n",
    "    env = GridWorldEnv(size=10)\n",
    "    agent = QLearningAgent()\n",
    "    visualizer = GridVisualizer(env)\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        path = [env.start]\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.update(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            path.append(env.current_pos)\n",
    "            \n",
    "        if episode % visualize_every == 0:\n",
    "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "    \n",
    "    return agent\n",
    "\n",
    "def find_path_and_visualize(agent, env, start, goal, animate=True):\n",
    "    \"\"\"Find path and visualize it with optional animation\"\"\"\n",
    "    path = [start]\n",
    "    current_state = env.reset(start=start, goal=goal)\n",
    "    done = False\n",
    "    \n",
    "    while not done and len(path) < 100:\n",
    "        action = agent.get_action(current_state)\n",
    "        print(action)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        path.append(next_state[0])\n",
    "        current_state = next_state\n",
    "    \n",
    "    print(f\"Path length: {len(path)-1}\")\n",
    "    print(f\"Path: {path}\")\n",
    "    visualizer = GridVisualizer(env)\n",
    "    if animate:\n",
    "        return visualizer.animate_path(path)\n",
    "    else:\n",
    "        visualizer.draw_grid(path)\n",
    "        plt.show()\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: 19\n",
      "Episode 200, Total Reward: 59\n",
      "Episode 400, Total Reward: -104\n",
      "Episode 600, Total Reward: -43\n",
      "Episode 800, Total Reward: 33\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create environment with some obstacles\n",
    "obstacles = [(2, 2), (2, 3), (2, 4), (3, 2), (4, 2)]\n",
    "env = GridWorldEnv(size=10, obstacles=obstacles)\n",
    "\n",
    "# Train the agent\n",
    "trained_agent = train(episodes=1000, visualize_every=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Path length: 99\n",
      "Path: [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (2, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (3, 0), (4, 0), (4, 0), (4, 0), (5, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (5, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0), (4, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Test and visualize with specific start and goal positions\n",
    "start_pos = (0, 0)\n",
    "goal_pos = (9, 9)\n",
    "anim = find_path_and_visualize(trained_agent, env, start_pos, goal_pos, animate=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_infoSpread",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
